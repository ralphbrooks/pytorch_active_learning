{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "% autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/36/67f809c135c17ec9b8276466cc57f35b98c240f55c780689ea29fa32f512/pip-20.0.1-py2.py3-none-any.whl (1.5MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5MB 4.5MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 19.3.1\n",
      "    Uninstalling pip-19.3.1:\n",
      "      Successfully uninstalled pip-19.3.1\n",
      "Successfully installed pip-20.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\n",
      "yes: standard output: Broken pipe\n",
      "yes: write error\n",
      "\u001b[31mERROR: tensorflow-serving-api 1.15.0 has requirement tensorflow~=1.15.0, but you'll have tensorflow 2.1.0rc2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-gpu 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-gpu 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 2.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorboard 2.1.0 has requirement grpcio>=1.24.3, but you'll have grpcio 1.10.1 which is incompatible.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!yes | pip uninstall -q tensorflow\n",
    "!pip install -q tensorflow==2.1.0rc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of six failed: Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 384, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 323, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 275, in update_class\n",
      "    old_obj = getattr(old, key)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/six.py\", line 93, in __get__\n",
      "    setattr(obj, self.name, result)  # Invokes __set__.\n",
      "AttributeError: 'NoneType' object has no attribute 'cStringIO'\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.1.0-rc2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !yes | pip uninstall tensorflow\n",
    "# ! pip install tensorflow-gpu==2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 2.], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([2.0, 2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import datetime\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "from random import shuffle\n",
    "from collections import defaultdict\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_evaluation_items = 1200 # annotate this many randomly sampled items first for evaluation data before creating training data\n",
    "minimum_training_items = 400 # minimum number of training items before we first train a model\n",
    "\n",
    "epochs = 10 # number of epochs per training session\n",
    "select_per_epoch = 200  # number to select per epoch per label\n",
    "\n",
    "\n",
    "data = []\n",
    "test_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directories with data\n",
    "unlabeled_data = \"unlabeled_data/unlabeled_data.csv\"\n",
    "\n",
    "evaluation_related_data = \"evaluation_data/related.csv\"\n",
    "evaluation_not_related_data = \"evaluation_data/not_related.csv\"\n",
    "\n",
    "#validation_related_data # not used in this example\n",
    "#validation_not_related_data # not used in this example\n",
    "\n",
    "training_related_data = \"training_data/related.csv\"\n",
    "training_not_related_data = \"training_data/not_related.csv\"\n",
    "\n",
    "\n",
    "already_labeled = {} # tracking what is already labeled\n",
    "feature_index = {} # feature mapping for one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath, skip_already_labeled=False):\n",
    "    # csv format: [ID, TEXT, LABEL, SAMPLING_STRATEGY, CONFIDENCE]\n",
    "    with open(filepath, 'r') as csvfile:\n",
    "        data = []\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            if skip_already_labeled and row[0] in already_labeled:\n",
    "        \t    continue\n",
    "        \t\t\n",
    "            if len(row) < 3:\n",
    "                row.append(\"\") # add empty col for LABEL to add later\n",
    "            if len(row) < 4:\n",
    "                row.append(\"\") # add empty col for SAMPLING_STRATEGY to add later        \n",
    "            if len(row) < 5:\n",
    "                row.append(0) # add empty col for CONFIDENCE to add later         \n",
    "            data.append(row)\n",
    "\n",
    "            label = str(row[2])\n",
    "            if row[2] != \"\":\n",
    "                textid = row[0]\n",
    "                already_labeled[textid] = label\n",
    "\n",
    "    csvfile.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_data(filepath, data):\n",
    "    with open(filepath, 'a', errors='replace') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows(data)\n",
    "    csvfile.close()\n",
    "\n",
    "def write_data(filepath, data):\n",
    "    with open(filepath, 'w', errors='replace') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows(data)\n",
    "    csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = load_data(training_related_data) + load_data(training_not_related_data)\n",
    "training_count = len(training_data)\n",
    "    \n",
    "evaluation_data = load_data(evaluation_related_data) + load_data(evaluation_not_related_data)\n",
    "evaluation_count = len(evaluation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(unlabeled_data, skip_already_labeled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1001927',\n",
       "  'wall st us shares drop aud rises despite interest rate cut',\n",
       "  '',\n",
       "  '',\n",
       "  0],\n",
       " ['17349', 'israeli soldiers reportedly kill three palestinians', '', '', 0],\n",
       " ['91445', 'quarantine concerns over changed wheat import', '', '', 0],\n",
       " ['791309', 'diocese had fair share of paedophilia; inquiry told', '', '', 0]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_annotations(data, default_sampling_strategy=\"random\"):\n",
    "    \"\"\"Prompts annotator for label from command line and adds annotations to data \n",
    "    \n",
    "    Keyword arguments:\n",
    "        data -- an list of unlabeled items where each item is \n",
    "                [ID, TEXT, LABEL, SAMPLING_STRATEGY, CONFIDENCE]\n",
    "        default_sampling_strategy -- strategy to use for each item if not already specified\n",
    "    \"\"\"\n",
    "\n",
    "    ind = 0\n",
    "    while ind <= len(data):\n",
    "        if ind < 0:\n",
    "            ind = 0 # in case you've gone back before the first\n",
    "        if ind < len(data):\n",
    "            textid = data[ind][0]\n",
    "            text = data[ind][1]\n",
    "            label = data[ind][2]\n",
    "            strategy =  data[ind][3]\n",
    "\n",
    "            if textid in already_labeled:\n",
    "                print(\"Skipping seen \"+label)\n",
    "                ind+=1\n",
    "            else:\n",
    "                print(annotation_instructions)\n",
    "                label = str(input(text+\"\\n\\n> \")) \n",
    "\n",
    "                if label == \"2\":                   \n",
    "                    ind-=1  # go back\n",
    "                elif label == \"d\":                    \n",
    "                    print(detailed_instructions) # print detailed instructions\n",
    "                elif label == \"s\":\n",
    "                    break  # save and exit\n",
    "                else:\n",
    "                    if not label == \"1\":\n",
    "                        label = \"0\" # treat everything other than 1 as 0\n",
    "                        \n",
    "                    data[ind][2] = label # add label to our data\n",
    "\n",
    "                    if data[ind][3] is None or data[ind][3] == \"\":\n",
    "                        data[ind][3] = default_sampling_strategy # add default if none given\n",
    "                    ind+=1        \n",
    "\n",
    "        else:\n",
    "            #last one - give annotator a chance to go back\n",
    "            print(last_instruction)\n",
    "            label = str(input(\"\\n\\n> \")) \n",
    "            if label == \"2\":\n",
    "                ind-=1\n",
    "            else:\n",
    "                ind+=1\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Classifier goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is there a way to just use a keras model and to feed the data without the use of tfrecords"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
