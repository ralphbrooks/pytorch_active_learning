{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "% autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Using cached https://files.pythonhosted.org/packages/54/0c/d01aa759fdc501a58f431eb594a17495f15b88da142ce14b5845662c13f3/pip-20.0.2-py2.py3-none-any.whl\n",
      "Installing collected packages: pip\n",
      "  Found existing installation: pip 19.3.1\n",
      "    Uninstalling pip-19.3.1:\n",
      "      Successfully uninstalled pip-19.3.1\n",
      "Successfully installed pip-20.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceed (y/n)? yes: standard output: Broken pipe\n",
      "yes: write error\n",
      "\u001b[31mERROR: tensorflow-serving-api 1.15.0 has requirement tensorflow~=1.15.0, but you'll have tensorflow 2.1.0rc2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorboard 2.1.0 has requirement grpcio>=1.24.3, but you'll have grpcio 1.10.1 which is incompatible.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!yes | pip uninstall -q tensorflow\n",
    "!pip install -q tensorflow==2.1.0rc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of six failed: Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 384, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 323, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 275, in update_class\n",
      "    old_obj = getattr(old, key)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/six.py\", line 93, in __get__\n",
      "    setattr(obj, self.name, result)  # Invokes __set__.\n",
      "AttributeError: 'NoneType' object has no attribute 'cStringIO'\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.1.0-rc2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !yes | pip uninstall tensorflow\n",
    "# ! pip install tensorflow-gpu==2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 2.], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([2.0, 2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import datetime\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "from random import shuffle\n",
    "from collections import defaultdict\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_evaluation_items = 1200 # annotate this many randomly sampled items first for evaluation data before creating training data\n",
    "minimum_training_items = 400 # minimum number of training items before we first train a model\n",
    "\n",
    "epochs = 10 # number of epochs per training session\n",
    "select_per_epoch = 200  # number to select per epoch per label\n",
    "\n",
    "\n",
    "data = []\n",
    "test_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directories with data\n",
    "unlabeled_data = \"../unlabeled_data/unlabeled_data.csv\"\n",
    "\n",
    "evaluation_related_data = \"../evaluation_data/related.csv\"\n",
    "evaluation_not_related_data = \"../evaluation_data/not_related.csv\"\n",
    "\n",
    "#validation_related_data # not used in this example\n",
    "#validation_not_related_data # not used in this example\n",
    "\n",
    "training_related_data = \"../training_data/related.csv\"\n",
    "training_not_related_data = \"../training_data/not_related.csv\"\n",
    "\n",
    "\n",
    "already_labeled = {} # tracking what is already labeled\n",
    "feature_index = {} # feature mapping for one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath, skip_already_labeled=False):\n",
    "    # csv format: [ID, TEXT, LABEL, SAMPLING_STRATEGY, CONFIDENCE]\n",
    "    with open(filepath, 'r') as csvfile:\n",
    "        data = []\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            if skip_already_labeled and row[0] in already_labeled:\n",
    "        \t    continue\n",
    "        \t\t\n",
    "            if len(row) < 3:\n",
    "                row.append(\"\") # add empty col for LABEL to add later\n",
    "            if len(row) < 4:\n",
    "                row.append(\"\") # add empty col for SAMPLING_STRATEGY to add later        \n",
    "            if len(row) < 5:\n",
    "                row.append(0) # add empty col for CONFIDENCE to add later         \n",
    "            data.append(row)\n",
    "\n",
    "            label = str(row[2])\n",
    "            if row[2] != \"\":\n",
    "                textid = row[0]\n",
    "                already_labeled[textid] = label\n",
    "\n",
    "    csvfile.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_data(filepath, data):\n",
    "    with open(filepath, 'a', errors='replace') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows(data)\n",
    "    csvfile.close()\n",
    "\n",
    "def write_data(filepath, data):\n",
    "    with open(filepath, 'w', errors='replace') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows(data)\n",
    "    csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = load_data(training_related_data) + load_data(training_not_related_data)\n",
    "training_count = len(training_data)\n",
    "    \n",
    "evaluation_data = load_data(evaluation_related_data) + load_data(evaluation_not_related_data)\n",
    "evaluation_count = len(evaluation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(unlabeled_data, skip_already_labeled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1001927',\n",
       "  'wall st us shares drop aud rises despite interest rate cut',\n",
       "  '',\n",
       "  '',\n",
       "  0],\n",
       " ['17349', 'israeli soldiers reportedly kill three palestinians', '', '', 0],\n",
       " ['91445', 'quarantine concerns over changed wheat import', '', '', 0],\n",
       " ['791309', 'diocese had fair share of paedophilia; inquiry told', '', '', 0]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_annotations(data, default_sampling_strategy=\"random\"):\n",
    "    \"\"\"Prompts annotator for label from command line and adds annotations to data \n",
    "    \n",
    "    Keyword arguments:\n",
    "        data -- an list of unlabeled items where each item is \n",
    "                [ID, TEXT, LABEL, SAMPLING_STRATEGY, CONFIDENCE]\n",
    "        default_sampling_strategy -- strategy to use for each item if not already specified\n",
    "    \"\"\"\n",
    "\n",
    "    ind = 0\n",
    "    while ind <= len(data):\n",
    "        if ind < 0:\n",
    "            ind = 0 # in case you've gone back before the first\n",
    "        if ind < len(data):\n",
    "            textid = data[ind][0]\n",
    "            text = data[ind][1]\n",
    "            label = data[ind][2]\n",
    "            strategy =  data[ind][3]\n",
    "\n",
    "            if textid in already_labeled:\n",
    "                print(\"Skipping seen \"+label)\n",
    "                ind+=1\n",
    "            else:\n",
    "                print(annotation_instructions)\n",
    "                label = str(input(text+\"\\n\\n> \")) \n",
    "\n",
    "                if label == \"2\":                   \n",
    "                    ind-=1  # go back\n",
    "                elif label == \"d\":                    \n",
    "                    print(detailed_instructions) # print detailed instructions\n",
    "                elif label == \"s\":\n",
    "                    break  # save and exit\n",
    "                else:\n",
    "                    if not label == \"1\":\n",
    "                        label = \"0\" # treat everything other than 1 as 0\n",
    "                        \n",
    "                    data[ind][2] = label # add label to our data\n",
    "\n",
    "                    if data[ind][3] is None or data[ind][3] == \"\":\n",
    "                        data[ind][3] = default_sampling_strategy # add default if none given\n",
    "                    ind+=1        \n",
    "\n",
    "        else:\n",
    "            #last one - give annotator a chance to go back\n",
    "            print(last_instruction)\n",
    "            label = str(input(\"\\n\\n> \")) \n",
    "            if label == \"2\":\n",
    "                ind-=1\n",
    "            else:\n",
    "                ind+=1\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_instructions = \"Please type 1 if this message is disaster-related, \"\n",
    "annotation_instructions += \"or hit Enter if not.\\n\"\n",
    "annotation_instructions += \"Type 2 to go back to the last message, \"\n",
    "annotation_instructions += \"type d to see detailed definitions, \"\n",
    "annotation_instructions += \"or type s to save your annotations.\\n\"\n",
    "\n",
    "last_instruction = \"All done!\\n\"\n",
    "last_instruction += \"Type 2 to go back to change any labels,\\n\"\n",
    "last_instruction += \"or Enter to save your annotations.\"\n",
    "\n",
    "detailed_instructions = \"A 'disaster-related' headline is any story about a disaster.\\n\"\n",
    "detailed_instructions += \"It includes:\\n\"\n",
    "detailed_instructions += \"  - human, animal and plant disasters.\\n\"\n",
    "detailed_instructions += \"  - the response to disasters (aid).\\n\"\n",
    "detailed_instructions += \"  - natural disasters and man-made ones like wars.\\n\"\n",
    "detailed_instructions += \"It does not include:\\n\"\n",
    "detailed_instructions += \"  - criminal acts and non-disaster-related police work\\n\"\n",
    "detailed_instructions += \"  - post-response activity like disaster-related memorials.\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_annotations(data, default_sampling_strategy=\"random\"):\n",
    "    \"\"\"Prompts annotator for label from command line and adds annotations to data \n",
    "    \n",
    "    Keyword arguments:\n",
    "        data -- an list of unlabeled items where each item is \n",
    "                [ID, TEXT, LABEL, SAMPLING_STRATEGY, CONFIDENCE]\n",
    "        default_sampling_strategy -- strategy to use for each item if not already specified\n",
    "    \"\"\"\n",
    "\n",
    "    ind = 0\n",
    "    # RAB - While index is less than min number of training instances needed\n",
    "    while ind <= len(data):\n",
    "        if ind < 0:\n",
    "            ind = 0 # in case you've gone back before the first\n",
    "        if ind < len(data):\n",
    "            textid = data[ind][0]\n",
    "            text = data[ind][1]\n",
    "            label = data[ind][2]\n",
    "            strategy =  data[ind][3]\n",
    "\n",
    "            if textid in already_labeled:\n",
    "                print(\"Skipping seen \"+label)\n",
    "                ind+=1\n",
    "            else:\n",
    "                print(annotation_instructions)\n",
    "                label = str(input(text+\"\\n\\n> \")) \n",
    "\n",
    "                if label == \"2\":                   \n",
    "                    ind-=1  # go back\n",
    "                elif label == \"d\":                    \n",
    "                    print(detailed_instructions) # print detailed instructions\n",
    "                elif label == \"s\":\n",
    "                    break  # save and exit\n",
    "                else:\n",
    "                    if not label == \"1\":\n",
    "                        label = \"0\" # treat everything other than 1 as 0\n",
    "                        \n",
    "                    data[ind][2] = label # add label to our data\n",
    "\n",
    "                    if data[ind][3] is None or data[ind][3] == \"\":\n",
    "                        data[ind][3] = default_sampling_strategy # add default if none given\n",
    "                    ind+=1        \n",
    "\n",
    "        else:\n",
    "            #last one - give annotator a chance to go back\n",
    "            print(last_instruction)\n",
    "            label = str(input(\"\\n\\n> \")) \n",
    "            if label == \"2\":\n",
    "                ind-=1\n",
    "            else:\n",
    "                ind+=1\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(minword = 3):\n",
    "    \"\"\"Create indexes for one-hot encoding of words in files\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # TODO - fully understand what is going on in this part of the example\n",
    "    # The first part is just a count of word frequency\n",
    "    total_training_words = {}\n",
    "    for item in data + training_data:\n",
    "        text = item[1]\n",
    "        for word in text.split():\n",
    "            if word not in total_training_words:\n",
    "                total_training_words[word] = 1\n",
    "            else:\n",
    "                total_training_words[word] += 1\n",
    "\n",
    "    for item in data + training_data:\n",
    "        text = item[1]\n",
    "        for word in text.split():\n",
    "            if word not in feature_index and total_training_words[word] >= minword:\n",
    "                feature_index[word] = len(feature_index)\n",
    "\n",
    "    return len(feature_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Linear is of the format $$y = xA^T + b$$\n",
    "\n",
    "```python\n",
    "nn.Linear(vocab_size, 128)\n",
    "```\n",
    "\n",
    "The above means that the input is the vocab size and the output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_size is returned directly\n",
    "# feature_index is populated indirectly\n",
    "vocab_size = create_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually going through the stuff in train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate to understand the information that is going into the pytorch model\n",
    "\n",
    "related = [row for row in training_data if '1' in row[2]]\n",
    "not_related = [row for row in training_data if '0' in row[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_data = related[:select_per_epoch]\n",
    "epoch_data += not_related[:select_per_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle(epoch_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
